{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "# cleaning + lowercase\n",
    "def cleanlower(ulasan):\n",
    "  ulasan = ulasan.str.replace(r\"[^a-zA-Z]\", ' ', regex=True)\n",
    "  ulasan = ulasan.str.lower()\n",
    "  return ulasan\n",
    "\n",
    "# stemming\n",
    "stem_factory = StemmerFactory()\n",
    "stemmer = stem_factory.create_stemmer() \n",
    "def stemming(ulasan):\n",
    "  ulasan = ulasan.apply(lambda x: stemmer.stem(x))\n",
    "  return ulasan\n",
    "\n",
    "#tokenizing\n",
    "def tokenizing(ulasan):\n",
    "  tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)\n",
    "  ulasan = ulasan.apply(lambda x: tokenizer.tokenize(x))\n",
    "  return ulasan\n",
    "\n",
    "#stopword\n",
    "# string_khusus = ['id','ulasan']\n",
    "url = 'https://raw.githubusercontent.com/appermana1/data/master/stopword.csv'\n",
    "stopword_import = pd.read_csv(url)\n",
    "stopword_custom = stopword_import['0']\n",
    "stopword_custom = stopword_custom.to_numpy()\n",
    "# print(stopword_custom)\n",
    "\n",
    "def stopwords(ulasan):\n",
    "    output= \" \".join([i for i in ulasan if i not in stopword_custom])\n",
    "    return output\n",
    "\n",
    "def preprocessing(ulasan):\n",
    "  b = cleanlower(ulasan)\n",
    "  c = stemming(b)\n",
    "  d = tokenizing(c)\n",
    "  e = d.apply(lambda x:stopwords(x))\n",
    "  return e\n",
    "\n",
    "#Split\n",
    "def split(ulasan):\n",
    "  ulasan = ulasan.str.split()\n",
    "  return ulasan\n",
    "\n",
    "def unique_term(word):\n",
    "  world = ''\n",
    "  for a in word:\n",
    "    world = np.union1d(a, world)\n",
    "  return world\n",
    "\n",
    "def bag_of_word(ulasan):\n",
    "\n",
    "  from sklearn.feature_extraction.text import CountVectorizer\n",
    "  coun_vect = CountVectorizer()\n",
    "  count_matrix = coun_vect.fit_transform(ulasan)\n",
    "  count_array = count_matrix.toarray()\n",
    "  df_bow = pd.DataFrame(data=count_array,columns = coun_vect.get_feature_names())\n",
    "  max_value = np.max(count_array)\n",
    "\n",
    "  bow = dict()\n",
    "  bow['max'] = max_value\n",
    "  bow['bow'] = df_bow\n",
    "  \n",
    "  return bow\n",
    "\n",
    "def fix_preprocessing(df_ulasan):\n",
    "  prp = preprocessing(df_ulasan)\n",
    "  df_bow = bag_of_word(prp)\n",
    "  cek_term = unique_term(tokenizing(prp))\n",
    "  return df_bow\n",
    "\n",
    "\n",
    "def normalize(bow, max_value_count):\n",
    "  for b in range(1, max_value_count+1):\n",
    "    for a in range(0, len(bow.columns)):\n",
    "      bow.iloc[:, [a]] = bow.iloc[:, [a]].replace(to_replace=b,value=1)\n",
    "  return bow\n",
    "\n",
    "\n",
    "\n",
    "def chi_label(df_bow, df_bow_label_column, var_label, term):\n",
    "  data_bow = df_bow[df_bow_label_column.isin([var_label])]\n",
    "  try:\n",
    "      #print(term,',',var_label)\n",
    "      jml_a = data_bow[term].value_counts()[1.0]\n",
    "  except KeyError:\n",
    "      jml_a = 0\n",
    "  try:\n",
    "      jml_c = data_bow[term].value_counts()[0.0]\n",
    "  except KeyError:\n",
    "      jml_c = 0\n",
    "  data_bow2 = df_bow[df_bow_label_column.ne(var_label)]\n",
    "  try:\n",
    "      jml_b = data_bow2[term].value_counts()[1.0]\n",
    "  except KeyError:\n",
    "      jml_b = 0\n",
    "  try:\n",
    "      jml_d = data_bow2[term].value_counts()[0.0]\n",
    "  except KeyError:\n",
    "      jml_d = 0\n",
    "  #rumus 3.1\n",
    "  chi_label = (jml_a*jml_d - jml_c*jml_b)**2/((jml_a + jml_c)*(jml_b + jml_d)*(jml_a + jml_b)*(jml_c + jml_d))\n",
    "  return chi_label\n",
    "\n",
    "\n",
    "\n",
    "def fix_chi_square(bow, max_value_count, df_label):\n",
    "  df_normal = normalize(bow,max_value_count)\n",
    "  df_process = pd.concat([df_label,df_normal], axis=1)\n",
    "  count_label = df_label.value_counts() #no index here \n",
    "  term = df_normal.columns\n",
    "  df_chi_square = pd.DataFrame({'term': []})\n",
    "  for x in term:\n",
    "    chi_total = 0 #inisiasi variabel harus disini\n",
    "    for y in range(0,len(count_label)):\n",
    "      label = count_label.index.tolist()[y]\n",
    "      chi_label_value = chi_label(df_process,df_process.iloc[:,0],label, x)     \n",
    "      #rumus 3.2\n",
    "      chi_total += chi_label_value\n",
    "    df_chi_square =df_chi_square.append({'term':x, 'Xtot':chi_total}, ignore_index=True)\n",
    "  df_chi_square['rank'] = df_chi_square['Xtot'].rank(ascending=False, method=\"first\")\n",
    "  df_chi_square_rank = df_chi_square.sort_values(by='rank', ignore_index=True)\n",
    "  return df_chi_square_rank\n",
    "\n",
    "\n",
    "\n",
    "def prob_prior(df_label):\n",
    "  total_ulasan = df_label.count()\n",
    "  count_label = df_label.value_counts() #no index here\n",
    "  df_prior = pd.DataFrame({'label': []})\n",
    "  for x in range(0,len(count_label)):\n",
    "    label = count_label.index.tolist()[x]\n",
    "    jml_p = count_label[label]\n",
    "    #rumus 3.3\n",
    "    prior = jml_p/total_ulasan\n",
    "    df_prior =df_prior.append({'label':label, 'prior':prior}, ignore_index=True)\n",
    "  return df_prior\n",
    "\n",
    "\n",
    "\n",
    "def transform_freq_table(df_label, bow):\n",
    "  df_process = pd.concat([df_label, bow], axis=1)\n",
    "  count_label = df_process.iloc[:,0].value_counts() #no index here\n",
    "  term = df_process.columns\n",
    "  df_prob_term = pd.DataFrame({'term': []})\n",
    "  for x in bow:\n",
    "    dict_prob = dict() #inisiasi dict harus disini\n",
    "    for y in range(0,len(count_label)):\n",
    "      label = count_label.index.tolist()[y]\n",
    "      data_bow = df_process[df_process.iloc[:,0].isin([label])]\n",
    "      jml = data_bow[x].sum()\n",
    "      dict_prob[label] = jml\n",
    "    dict_prob['term']=x #input dict harus disini\n",
    "    df_prob_term = df_prob_term.append(dict_prob, ignore_index=True) #append dict harus disini\n",
    "  return df_prob_term\n",
    "\n",
    "\n",
    "\n",
    "def prob_likelihood(df_label_prior,df_term,df_freq_table):\n",
    "  jml_all_term = 0\n",
    "  for p in df_label_prior:\n",
    "    jml = df_freq_table[p].agg('sum')\n",
    "    jml_all_term += jml\n",
    "  df_pct = pd.DataFrame({'term': []})\n",
    "  for x in df_term:\n",
    "    dict_pct = dict()\n",
    "    # term = df_freq_table.iloc[x, 0] #there is an index here\n",
    "    for y in df_label_prior:\n",
    "      freq_c = df_freq_table[y].agg('sum')\n",
    "      search_term = df_freq_table.loc[(df_freq_table['term']==x)]\n",
    "      for z in search_term[y]:\n",
    "        freq_tc = z\n",
    "      # print(freq_tc)\n",
    "      #rumus 3.4\n",
    "      pct_value = (freq_tc+1)/(freq_c+jml_all_term)\n",
    "      dict_pct[y] = pct_value\n",
    "    dict_pct['term']=x\n",
    "    df_pct = df_pct.append(dict_pct, ignore_index=True)\n",
    "  return df_pct\n",
    "\n",
    "\n",
    "\n",
    "def validate_test_bow(test_bow,df_likelihood_term):\n",
    "  df_validate= pd.DataFrame()  \n",
    "  for a in test_bow:\n",
    "    for term in df_likelihood_term:\n",
    "      if a == term:\n",
    "        df_validate[a]=test_bow[a]\n",
    "  return df_validate\n",
    "\n",
    "\n",
    "def prob_posterior_doc(df_prior,prior_label,max_values_test_bow,validate_test_bow,df_likelihood,df_likelihood_term):\n",
    "  doc_prob = pd.DataFrame()\n",
    "  for label in prior_label:\n",
    "    dict_replace_value = dict()\n",
    "    dict_replace_value = validate_test_bow.copy()\n",
    "    for term in validate_test_bow:\n",
    "      get_term = df_likelihood[df_likelihood_term==term]\n",
    "      get_value = get_term[label]\n",
    "      for c in get_value: \n",
    "        dict_replace_value[term] = dict_replace_value[term]*c\n",
    "    likelihood = dict_replace_value.sum(axis=1)\n",
    "    get_prior_value = df_prior[prior_label==label]\n",
    "    for prior in get_prior_value['prior']:\n",
    "\n",
    "      #rumus 3.7\n",
    "      doc_prob[label] = prior*likelihood\n",
    "      \n",
    "  return doc_prob\n",
    "\n",
    "\n",
    "def predict_doc(prob_doc,df_test_ulasan,df_test, validate_bow):\n",
    "  df_pred = pd.DataFrame()\n",
    "  # print(prob_doc)\n",
    "  max_values = prob_doc.max(axis = 1)\n",
    "  df_pred = pd.concat([df_test,prob_doc], axis=1)\n",
    "  for i in range(0,len(df_test_ulasan)):\n",
    "    df_pred['pred']=0.0\n",
    "  \n",
    "  for i in range(0,len(df_test_ulasan)):\n",
    "    if max_values[i]!=0:\n",
    "      for x in prob_doc:\n",
    "        if prob_doc[x][i]==max_values[i]:\n",
    "          df_pred['pred'][i] = x #kolom pred harus inisiasi jml baris\n",
    "          # print(x)\n",
    "  return df_pred\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_dataset(df_train,used_feature_selection, chi_square):\n",
    "\n",
    "  v_limit = chi_square['rank'].quantile(used_feature_selection)\n",
    "\n",
    "  selection = chi_square[chi_square['rank'] <= v_limit]\n",
    "\n",
    "  bow = fix_preprocessing(df_train['ulasan'])\n",
    "\n",
    "  df_prob_prior = prob_prior(df_train['GT'])\n",
    "\n",
    "  pivot_table = transform_freq_table(df_train['GT'],bow['bow'])\n",
    "\n",
    "  df_prob_likelihood = prob_likelihood(df_prob_prior['label'],selection['term'],pivot_table)\n",
    "\n",
    "  train = dict()\n",
    "  train['df_prior'] = df_prob_prior\n",
    "  train['df_likelihood'] = df_prob_likelihood\n",
    "  train['df_rank'] = selection\n",
    "\n",
    "  return train\n",
    "\n",
    "\n",
    "def predict_dataset(df_test,df_prior,df_likelihood):\n",
    "  test_bow = fix_preprocessing(df_test['ulasan'])\n",
    "\n",
    "  test_validate = validate_test_bow(test_bow['bow'],df_likelihood['term'])\n",
    "\n",
    "  prob_doc = prob_posterior_doc(df_prior,df_prior['label'],test_bow['max'],test_validate,df_likelihood,df_likelihood['term'])\n",
    "\n",
    "  pred = predict_doc(prob_doc,df_test['ulasan'],df_test,test_validate)\n",
    "\n",
    "  test = dict()\n",
    "  test['pred'] = pred\n",
    "  test['validate'] = test_validate\n",
    "\n",
    "  return test\n",
    "\n",
    "\n",
    "\n",
    "def performance_test(y_test, y_pred):\n",
    "  #importing confusion matrix\n",
    "  from sklearn.metrics import confusion_matrix\n",
    "  confusion = confusion_matrix(y_test, y_pred)\n",
    "  print('Confusion Matrix\\n')\n",
    "  print(confusion)\n",
    "\n",
    "  #importing accuracy_score, precision_score, recall_score, f1_score\n",
    "  from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "  print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "  print('Micro Precision: {:.2f}'.format(precision_score(y_test, y_pred, average='micro')))\n",
    "  print('Micro Recall: {:.2f}'.format(recall_score(y_test, y_pred, average='micro')))\n",
    "  print('Micro F1-score: {:.2f}\\n'.format(f1_score(y_test, y_pred, average='micro')))\n",
    "\n",
    "  print('Macro Precision: {:.2f}'.format(precision_score(y_test, y_pred, average='macro')))\n",
    "  print('Macro Recall: {:.2f}'.format(recall_score(y_test, y_pred, average='macro')))\n",
    "  print('Macro F1-score: {:.2f}\\n'.format(f1_score(y_test, y_pred, average='macro')))\n",
    "\n",
    "  print('Weighted Precision: {:.2f}'.format(precision_score(y_test, y_pred, average='weighted')))\n",
    "  print('Weighted Recall: {:.2f}'.format(recall_score(y_test, y_pred, average='weighted')))\n",
    "  print('Weighted F1-score: {:.2f}'.format(f1_score(y_test, y_pred, average='weighted')))\n",
    "\n",
    "  from sklearn.metrics import classification_report\n",
    "  print('\\nClassification Report\\n')\n",
    "  print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def get_min_required_rows(test_size):\n",
    "    return 1 / test_size\n",
    "\n",
    "def make_stratified_splits(df, y_col, test_size):\n",
    "    \"\"\"\n",
    "        for any class with rows less than min_required_rows corresponding to the input test_size,\n",
    "        all the rows associated with the specific class will have a copy in both the train and test splits.\n",
    "        \n",
    "        example: if test_size is 0.2 (20% otherwise),\n",
    "        min_required_rows = 5 (which is obtained from 1 / test_size i.e., 1 / 0.2)\n",
    "        where the resulting splits will have 4 train rows (80%), 1 test row (20%)..\n",
    "    \"\"\"\n",
    "    \n",
    "    id_col = \"no\"\n",
    "    temp_col = \"same-class-rows\"\n",
    "    \n",
    "    class_to_counts = df[y_col].value_counts()\n",
    "    df[temp_col] = df[y_col].apply(lambda y: class_to_counts[y])\n",
    "    \n",
    "    min_required_rows = get_min_required_rows(test_size)\n",
    "    copy_rows = df[df[temp_col] < min_required_rows].copy(deep=True)\n",
    "    valid_rows = df[df[temp_col] >= min_required_rows].copy(deep=True)\n",
    "    \n",
    "    X = valid_rows[id_col].tolist()\n",
    "    y = valid_rows[y_col].tolist()\n",
    "    \n",
    "    # notice, this train_test_split is a stratified split\n",
    "    X_train, X_test, _, _ = train_test_split(X, y, test_size=test_size, random_state=1, stratify=y)\n",
    "    \n",
    "    # X_test = X_test + copy_rows[id_col].tolist()\n",
    "    X_train = X_train + copy_rows[id_col].tolist()\n",
    "    \n",
    "    df.drop([temp_col], axis=1, inplace=True)\n",
    "    \n",
    "    test_df = df[df[id_col].isin(X_test)].copy(deep=True)\n",
    "    train_df = df[df[id_col].isin(X_train)].copy(deep=True)\n",
    "    \n",
    "    print (f\"number of rows in the original dataset: {len(df)}\")\n",
    "    \n",
    "    test_prop = round(len(test_df) / len(df) * 100, 2)\n",
    "    train_prop = round(len(train_df) / len(df) * 100, 2)\n",
    "    print (f\"number of rows in the splits: {len(train_df)} ({train_prop}%), {len(test_df)} ({test_prop}%)\")\n",
    "\n",
    "    dfy = dict()\n",
    "    dfy['train'] = train_df\n",
    "    dfy['test'] = test_df\n",
    "    \n",
    "    return dfy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows in the original dataset: 3000\n",
      "number of rows in the splits: 2415 (80.5%), 585 (19.5%)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset = pd.read_csv('data/dataset.csv')\n",
    "dataset['split'] = dataset['entity'].astype(str) + \"_\" + dataset['GT'].astype(str)\n",
    "\n",
    "coba = make_stratified_splits(dataset, y_col=\"split\", test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = coba['train']\n",
    "df_test = coba['test'][['no','entity','ulasan','GT']]\n",
    "df_test = df_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_bow = fix_preprocessing(dataset['ulasan'])\n",
    "chi_square = fix_chi_square(new_bow['bow'],new_bow['max'], df_train['GT'])\n",
    "\n",
    "train_data = train_dataset(dataset,1,chi_square)\n",
    "df_prior = train_data['df_prior']\n",
    "df_likelihood = train_data['df_likelihood']\n",
    "pd.to_pickle(train_data,r'train_model.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[446   0   0]\n",
      " [ 66   0   0]\n",
      " [ 63   0   0]]\n",
      "\n",
      "Accuracy: 0.78\n",
      "\n",
      "Micro Precision: 0.78\n",
      "Micro Recall: 0.78\n",
      "Micro F1-score: 0.78\n",
      "\n",
      "Macro Precision: 0.26\n",
      "Macro Recall: 0.33\n",
      "Macro F1-score: 0.29\n",
      "\n",
      "Weighted Precision: 0.60\n",
      "Weighted Recall: 0.78\n",
      "Weighted F1-score: 0.68\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           D       0.78      1.00      0.87       446\n",
      "           N       0.00      0.00      0.00        66\n",
      "          TD       0.00      0.00      0.00        63\n",
      "\n",
      "    accuracy                           0.78       575\n",
      "   macro avg       0.26      0.33      0.29       575\n",
      "weighted avg       0.60      0.78      0.68       575\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-070447cab032>:236: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pred['pred'][i] = x #kolom pred harus inisiasi jml baris\n",
      "c:\\Python\\Python38-32\\lib\\site-packages\\pandas\\core\\indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iloc._setitem_with_indexer(indexer, value)\n",
      "c:\\Python\\Python38-32\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Python\\Python38-32\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "prediksi = predict_dataset(df_test,df_prior,df_likelihood)\n",
    "df_prediksi = prediksi['pred']\n",
    "df_prediksi = df_prediksi[df_prediksi['pred']!=0]\n",
    "hasil = performance_test(df_prediksi['GT'],df_prediksi['pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "www3 = pd.read_pickle(r'train_model.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>prior</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D</td>\n",
       "      <td>0.747412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N</td>\n",
       "      <td>0.132505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TD</td>\n",
       "      <td>0.120083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label     prior\n",
       "0     D  0.747412\n",
       "1     N  0.132505\n",
       "2    TD  0.120083"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "www3['df_likelihood']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 32-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bea294ee008d20969dc05d3aa98cf932d33529394c06cf2ff24ec82670e3759e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
